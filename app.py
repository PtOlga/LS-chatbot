import os
import streamlit as st
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import InMemoryVectorStore
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–µ—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ)
load_dotenv(verbose=True)

# –ó–∞–≥—Ä—É–∂–∞–µ–º API-–∫–ª—é—á–∏ —á–µ—Ä–µ–∑ Streamlit secrets (–¥–ª—è –æ–±–ª–∞—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)
GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", None)
USER_AGENT = st.secrets.get("USER_AGENT", None)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–¥–∞–Ω—ã –ª–∏ API-–∫–ª—é—á–∏
if not GROQ_API_KEY:
    st.error("–û—à–∏–±–∫–∞: GROQ_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()
if not USER_AGENT:
    st.error("–û—à–∏–±–∫–∞: USER_AGENT –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM
llm = ChatGroq(
    model_name="llama-3.3-70b-versatile",
    temperature=0.6,
    api_key=GROQ_API_KEY
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embeddings_model = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large-instruct")

# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
def load_english_pages(urls):
    english_docs = []
    
    for url in urls:
        if not any(lang in url for lang in ["/ru", "/ar", "/es", "/ch"]):  
            loader = WebBaseLoader(url)  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ø–µ—Ä–µ–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É
            documents = loader.load()
            english_docs.extend(documents)
    
    return english_docs

# –ü—Ä–∏–º–µ—Ä URL, –≥–¥–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
urls = ["https://status.law/about", "https://status.law/ru/about", "https://status.law/ar/contact"]
documents = load_english_pages(urls)

# –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
chunks = text_splitter.split_documents(documents)

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
vector_store = InMemoryVectorStore.from_documents(chunks, embeddings_model)
retriever = vector_store.as_retriever()

# –ü—Ä–æ–º–ø—Ç –¥–ª—è –±–æ—Ç–∞
template = """
You are a helpful legal assistant that answers questions based on information from status.law.

Answer accurately and concisely.

Question: {question}

Only use the provided context to answer the question.

Context: {context}
"""

prompt = PromptTemplate.from_template(template)

# –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
def format_history(message_history):
    formatted = ""
    for msg in message_history:
        formatted += f"User: {msg['question']}\nBot: {msg['answer']}\n\n"
    return formatted

message_history = []

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit
st.set_page_config(page_title="Legal Chatbot", page_icon="ü§ñ")
st.title("ü§ñ Legal Chatbot")
st.write("–≠—Ç–æ—Ç –±–æ—Ç –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Å–∞–π—Ç–∞ status.law.")

# –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ –≤–æ–ø—Ä–æ—Å–∞
user_input = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:")

if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å"):
    if user_input:
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
        chain = (
            RunnableLambda(lambda x: {"context": retriever.get_relevant_documents(x["question"])})  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
            | prompt
            | llm
            | StrOutputParser()
        )

        # –ó–∞–ø—É—Å–∫ —Ü–µ–ø–æ—á–∫–∏
        response = chain.invoke({"question": user_input})

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        message_history.append({"question": user_input, "answer": response})

        # –í—ã–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç
        st.write(response)
